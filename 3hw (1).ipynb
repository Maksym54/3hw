{
  "metadata": {
    "kernelspec": {
      "name": "python",
      "display_name": "Python (Pyodide)",
      "language": "python"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "python",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat_minor": 4,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "code",
      "source": "import numpy as np\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler",
      "metadata": {
        "trusted": true,
        "id": "Y_Nd8JwEQR6b"
      },
      "outputs": [],
      "execution_count": 29
    },
    {
      "cell_type": "code",
      "source": "data = pd.read_csv(\"Housing.csv\")\nprint(data.head())",
      "metadata": {
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 339
        },
        "id": "dPMF0b4ZQR6e",
        "outputId": "d3fd7d7c-dab6-49b2-c6d9-0fec063bd773"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "      price  area  bedrooms  bathrooms  stories mainroad guestroom basement  \\\n0  13300000  7420         4          2        3      yes        no       no   \n1  12250000  8960         4          4        4      yes        no       no   \n2  12250000  9960         3          2        2      yes        no      yes   \n3  12215000  7500         4          2        2      yes        no      yes   \n4  11410000  7420         4          1        2      yes       yes      yes   \n\n  hotwaterheating airconditioning  parking prefarea furnishingstatus  \n0              no             yes        2      yes        furnished  \n1              no             yes        3       no        furnished  \n2              no              no        2      yes   semi-furnished  \n3              no             yes        3      yes        furnished  \n4              no             yes        2       no        furnished  \n",
          "output_type": "stream"
        }
      ],
      "execution_count": 30
    },
    {
      "cell_type": "code",
      "source": "def h(X, w):\n    return np.dot(X, w)",
      "metadata": {
        "trusted": true,
        "id": "tjl9EJvaQR6e",
        "outputId": "22a31e0f-7b5c-4eb7-9c7b-2b12cd1f288c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 158
        }
      },
      "outputs": [],
      "execution_count": 42
    },
    {
      "cell_type": "code",
      "source": "def loss_function(X, y, w):\n    return np.square(h(X, w) - y).sum() / (2 * len(X))",
      "metadata": {
        "trusted": true,
        "id": "7Y1A--MiQR6f",
        "outputId": "eb204ac9-66f4-4852-db5a-a5bd4567342d"
      },
      "outputs": [],
      "execution_count": 43
    },
    {
      "cell_type": "code",
      "source": "def gradient_step(X, y, w, learning_rate):\n    m = len(y)\n    grad = (X.T @ (h(X, w) - y)) / m\n    w -= learning_rate * grad\n    return w",
      "metadata": {
        "trusted": true,
        "id": "xL6VzhFiQR6f",
        "outputId": "10e4be6e-fa07-4e60-c576-33cb44c9c7c7"
      },
      "outputs": [],
      "execution_count": 49
    },
    {
      "cell_type": "code",
      "source": "def hypothesis(X, w):\n    return X @ w",
      "metadata": {
        "trusted": true,
        "id": "UH3T22IKQR6f"
      },
      "outputs": [],
      "execution_count": 50
    },
    {
      "cell_type": "code",
      "source": "def loss(X, y, w):\n    m = y.shape[0]\n    h = hypothesis(X, w)\n    J = (1/(2*m)) * np.sum((h - y)**2)\n    return J",
      "metadata": {
        "trusted": true,
        "id": "r86TnjjpQR6f"
      },
      "outputs": [],
      "execution_count": 51
    },
    {
      "cell_type": "code",
      "source": "def gradient(X, y, learning_rate, num_iter, eps):\n    ones = np.ones((X.shape[0], 1))\n    X = np.hstack((ones, X))\n\n    w = np.zeros(X.shape[1])\n\n    loss = loss_function(X, y, w)\n    loss_history = [loss]\n\n    for _ in range(num_iter):\n        w = gradient_step(X, y, w, learning_rate)\n\n        loss = loss_function(X, y, w)\n        if abs(loss - loss_history[-1]) < eps:\n            loss_history.append(loss)\n            break\n\n        loss_history.append(loss)\n\n    return w, loss_history",
      "metadata": {
        "trusted": true,
        "id": "6s4MB-a_QR6g"
      },
      "outputs": [],
      "execution_count": 54
    },
    {
      "cell_type": "code",
      "source": "df = pd.read_csv(\"Housing.csv\")\nnorm = df.copy()\ncolumns = ['price', 'area', 'bedrooms', 'bathrooms']\nfor column in columns[1:]:\n    norm[column] = (df[column] - df[column].mean()) / df[column].std()\n\nX = norm[['area', 'bathrooms', 'bedrooms']].values\ny = norm['price'].values\n\nlearning_rate = 0.001\nnum_iter = 100000\neps = 1e-12\n\nw_gradient, loss_history = gradient(X, y, learning_rate, num_iter, eps)\nprint('Gradient Descent - w:', w_gradient)\n\nones = np.ones((X.shape[0], 1))\nX = np.hstack((ones, X))\nw_analytical = np.linalg.pinv(X.T @ X) @ X.T @ y\nprint('Analytical Solution - Optimal w:', w_analytical)",
      "metadata": {
        "trusted": true,
        "id": "3Av1MzNjQR6g"
      },
      "outputs": [
        {
          "ename": "<class 'NameError'>",
          "evalue": "name 'gradient_step' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[48], line 14\u001b[0m\n\u001b[1;32m     11\u001b[0m num_iter \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m100000\u001b[39m\n\u001b[1;32m     12\u001b[0m eps \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1e-12\u001b[39m\n\u001b[0;32m---> 14\u001b[0m w_gradient, loss_history \u001b[38;5;241m=\u001b[39m \u001b[43mgradient\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_iter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meps\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mGradient Descent - w:\u001b[39m\u001b[38;5;124m'\u001b[39m, w_gradient)\n\u001b[1;32m     17\u001b[0m ones \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mones((X\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;241m1\u001b[39m))\n",
            "Cell \u001b[0;32mIn[47], line 11\u001b[0m, in \u001b[0;36mgradient\u001b[0;34m(X, y, learning_rate, num_iter, eps)\u001b[0m\n\u001b[1;32m      8\u001b[0m loss_history \u001b[38;5;241m=\u001b[39m [loss]\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_iter):\n\u001b[0;32m---> 11\u001b[0m     w \u001b[38;5;241m=\u001b[39m \u001b[43mgradient_step\u001b[49m(X, y, w, learning_rate)\n\u001b[1;32m     13\u001b[0m     loss \u001b[38;5;241m=\u001b[39m loss_function(X, y, w)\n\u001b[1;32m     14\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mabs\u001b[39m(loss \u001b[38;5;241m-\u001b[39m loss_history[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]) \u001b[38;5;241m<\u001b[39m eps:\n",
            "\u001b[0;31mNameError\u001b[0m: name 'gradient_step' is not defined"
          ],
          "output_type": "error"
        }
      ],
      "execution_count": 48
    },
    {
      "cell_type": "code",
      "source": "",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    }
  ]
}